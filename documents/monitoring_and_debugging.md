# 모니터링과 디버깅

여기서는 스파크 어플리케이션 모니터링과 디버깅에 필요한 주요 내용을 소개한다.

그리고 스파크 Job 의 라이프사이클을 추적하는 방법을 이해하기 위해서 예제 쿼리와 스파크 UI 를 함께 살펴보겠다.

### 모니터링 범위

- 스파크 잡에서 문제가 생기면 오류를 파악하기 위해서 스파크 잡을 모니터링 해야한다.
- 그러므로 모니터링을 하기위해 모니터링 대상과 필요한 옵션을 살펴보자.
- 모니터링 대상은 다음과 같다.
    - 스파크 어플리케이션 잡
        - 클러스터에서 사용자 어플리케이션이 사용되는 상황을 파악하려면 스파크 UI 와 스파크 로그를 확인해야 한다.
        - 스파크 UI 는 실행중인 어프릴케이션의 RDD 와 쿼리 실행 계획 같은 개념의 정보를 준다.
    - JVM
        - 스파크는 모든 익스큐터를 JVM 위에서 실행한다.
        - 그래서 각 **코드가 실행되는 과정**을 보고 이해하고 싶다면 JVM 을 모니터링 해야한다.
        - JVM 도구에는 Stack Trace 를 제공하는 jstack, 힙 덤프 (Heap dump) 를 생성하는 jmap, 시계열 통계 리포트를 제공해주는 jstat, 다양한 JVM 속성 변수를 시각화된 방식으로 탐색할 수 있는 jconsole 등이 있다. 이들 도구는 모두 JVM 내부 동작 방식을 이해하는 데 도움이 된다.
        - 이 중 일부 정보는 스파크 UI 에서 확인할 수 있지만 저수준의 디버깅이 필요하다면 JVM 도구가 더 유용하다.
    - OS 와 머신
        - JVM 은 OS 위에서 동작한다. 따라서 해당 머신이 제대로 동작할 수 있는 상태인지 확인하는 것도 중요하다. 따라서 CPU, I/O, 네트워크 등의 자원에 대한 모니터링도 함께 해야한다.
        - dtat, iostat, 그리고 iotop 같은 명령을 이용하면 더 세밀하게 모니터링 할 수 있다.
    - 클러스터
        - 스파크 어플리케이션이 실행되는 클러스터도 모니터링 해야한다. 여기서는 클러스터 매니저가 모니터링 대상이다.
        - 클러스터 모니터링 도구로는 프로메테우스가 있다.

  ### 모니터링 대상

    - 모니터링 대상을 간략하게 살펴본 다음, 스파크 어플리케이션을 모니터링하고 디버깅하는 방법을 알아보자.
    - 모니터링 대상은 다음과 같이 크게 두 가지로 나눌 수 있다.
        - 실행 중인 사용자 어플리케이션의 프로세스 (CPU, 메모리 사용량)
        - 프로세스 내부에서의 쿼리 실행 과정 (잡과 테스크)

  ### 드라이버와 익스큐터 프로세스

    - 스파크 어플리케이션을 모니터링 할 때는 스파크 드라이버를 관찰해야한다. 스파크 드라이버에 모든 어플리케이션의 상태가 보관되어 있으며, 안정적으로 실행 중인지 확인할 수 있다.

  ### 쿼리, 잡, 스테이지, 테스크

    - 드라이버와 익스큐터 프로세스에 대한 모니터링도 중요하지만 특정 쿼리에서 무슨 일이 일어나는지 확인해야 할 때도 있다.
    - 스파크는 **쿼리, 잡, 스테이지, 그리고 테스크**의 개념을 가지고 있으며 각각의 정보를 확인할 수 있다.
    - 이러한 정보는 클러스터에서 특정 시점에 실행되는 작업을 파악하는게 가능하고 성능 개선이나 디버깅 시 매우 유용하다.


  ## 스파크 로그 
  
  - 스파크를 가장 상세하게 모니터링 하는 방법 중 하나는 로그 파일을 살펴보는 것. 
  - 스파크 애플리케이션의 로그나 스파크 자체의 발견한 이벤트는 잡의 실패 지점과 원인을 파악하는데 도움이 된다. 
  - `spark.sparkContext.setLogLevel("INFO")` 를 통해서 스파크의 로그 수준을 변경하는게 가능하다.  
  - 로깅 프레임워크를 사용한다면 스파크 로그와 함께 사용자가 필요한 정보도 로그로 기록하는게 가능하고 스파크와 애플리케이션 모두 점검하는게 가능하다. 
  - 클러스터에서 스파크를 실행한다면 클러스터 매니저로 파일에 로그를 저장하는 것도 가능하다. 이건 클러스터 매니저 공식 문서에서 로그 파일을 찾는 방법을 찾아보자. 


  ## 스파크 UI 
  - 스파크 UI 는 실행중인 어플리케이션과 스파크 워크로드에 대한 평가지표를 모니터링하는데 사용할 수 있다. 
  - 사용자는 스파크 UI 탭에서 모니터링하려는 항목에 접근하는게 가능하다. 
    - Jobs: 스파크 잡에 대한 정보를 제공한다.
    - Stages: 개별 스테이지 (스테이지의 테스크를 포함한다.) 와 관련된 정보를 제공한다.
    - Storage: 스파크 애플리케이션에 캐싱된 정보와 데이터 정보를 제공한다. 
    - Environment: 스파크 어플리케이션의 구성과 설정 관련 정보를 제공한다. 
    - Executors: 애플리케이션에서 사용 중인 익스큐터의 상세 정보를 제공한다.  
    - SQL: SQL 과 DataFrame 을 포함한 구조적 API 쿼리 정보를 제공한다.
  
  ## 추가) 스파크 어플리케이션의 라이프사이클 (내부)

    - 우리가 짠 코드는 스파크 어플리케이션에서 하나 이상의 스파크 잡으로 구성된다. 스레드를 이용해서 여러 액션을 병렬적으로 실행하는게 아니라면 스파크 잡은 차례대로 실행된다.

  ### SparkSession

    - 모든 어플리케이션에서 가장 먼저 SparkSession 을 만든다.
    - 기존 코드에서는 new SparkContext 로 만들 수 있지만 SparkSession 의 빌더 메소드를 사용해서 객체를 생성하는게 더 안전하다. 스파크 어플리케이션에서 다수의 라이브러리가 세션을 생성하려는 상황에서 컨택스트 충돌을 방지할 수 있기 때문이다.
    - SparkSesion 은 스파크 2.x 버전에서만 사용할 수 있고 과거 버전에서는 스파크의 구조적 API 를 사요하기 위해서는 SparkSession 대신에 SparkContext 와 SQLContext 를 직접 생성했다.

    ```scala
    val spark = SparkSession.builder()
    	.appName("Spark Example")
    	.config("spark.sql.warehouse.dir", "/user/hive/warehouse")
    	.getOrCreate()
    ```

  ### SparkContext

    - SparkSession 의 SparkContext 는 스파크 클러스터에 대한 연결이다.
    - SparkContext 를 이용해서 RDD 와 같은 저수준의 API 를 사용하는게 가능하다.

  ### 논리적 명령 (≠ 선언적 명령)

    - 스파크 코드는 트랜스포메이션과 액션으로 구성된다.
    - 사용자는 SQL, RDD 처리, 머신러닝 알고리즘 등을 사용해서 트랜스포메이션과 액션을 마음대로 구성하는게 가능하다.
    - 그러므로 DataFrame 과 같은 선언적 명령을 사용하는 방법과 논리적 명령이 어떻게 실행계획으로 변환되는지 이해하는 것도 중요하다. 이를 기반으로 스파크가 클러스터에서 동작하는 방식을 이해할 수 있기 떄문이다.

### 스파크 잡, 스테이지, 테스크

- Job > Stage > Task 순으로 계층이 이뤄져있다.
- 보통 하나의 액션은 하나의 Job 으로 구성된다.
- Stage 는 Executor 들이 모두 해당 스테이지에 같은 테스크들을 하는 것을 말한다. 예로 정렬을 하거나 그룹핑을 하는 작업이 일어나면 데이터들을 셔플해야 하므로 새로운 스테이지들 만든다.
- 테스크는 단일 Executor 에서 트랜스포메이션 처리를 하는 것을 말한다.

## 스파크 로그

- 스파크 로그를 통해서 Job 의 실패 지점이나 원인을 파악하는데 도움이 된다.
- 로깅 프레임워크를 사용한다면 스파크 로그와 함께 사용자 로그를 모두 기록할 수 있으므로 스파크 어플리케이션을 점검하는게 가능하다.

## 스파크 UI

- 스파크 UI 는 실행중인 스파크 어플리케이션과 스파크 워크로드에 대한 평가지표를 모니터링할 수 있다.
- 사용자는 스파크 UI 탭에서 모니터링 할려는 항목에 접근할 수 있다.
    - Jobs: 스파크 잡에 대한 정보를 제공한다.
    - Stages: 개별 스테이지와 테스크에 관한 정보를 제공한다.
    - Storage: 스파크 어플리케이션에 캐싱된 정보와 데이터 정보를 제공한다.
    - Environment: 스파크 어플리케이션의 구성과 설정 관련 정보를 제공한다.
    - Executor: 어플리케이션에서 사용중인 익스큐터의 상세 정보를 제공한다.
    - SQL: SQL 과 DataFrame 을 포함한 구조적 API 쿼리 정보를 제공한다.


## 디버깅 및 스파크 응급 처치

- 이제부터 스파크 디버깅 및 스파크에서 문제가 생겼을 때 해결하는 방법에 대해서 알아보겠다.
- 여기서 나오는 문제는 스파크 내부에서 발생하는 OutofMemoryError 와 사용자가 경험할 수 있는 테스크의 처리가 느린 경우 등이 있다.

### 스파크 어플리케이션이 시작되지 않는 경우

- 스파크의 잡이 시작되지 않거나
- 스파크 UI 가 드라이버 노드를 제외한 클러스터 노드 정보를 표현하지 않는 경우
- 스파크 UI 가 잘못된 정보를 표시하는 경우가 있다.
- 이런 문제는 스파크 클러스터를 구축하는 과정에서 생기는 것이다.
- 대응법은 다음과 같다.
    - 설정한 포트로 클러스터 머신간에 통신할 수 있는지 확인하자.
    - 클러스터 매니저가 스파크를 실행할 수 있는지 적합한지 확인하자.
    - 스파크의 자원 설정ㅇ이 올바른지 확인하자.

### 스파크 어플리케이션 실행 전에 오류가 발생한 경우

- 어플리케이션이 클러스터에서 실행할 때 발생할 수 있는 경우로
- 명령이 전혀 실행되지 않고 오류메시지가 출력되거나
- 스파크 UI 에서 잡, 스테이지, 테스크 정보를 확인할 수 없는 경우다.
- 대응법은 다음과 같다.
    - 스파크 UI 의 Environment 탭에서 어플리케이션 정보를 확인하자. 오타가 있는지 등을 확인하자.
    - 잘못된 버전의 저장소 라이브러리를 사용하는지 확인해보자.
    - 잘못된 입력 파일 경로나 필드명을 사용하는건지 확인해보자.

### 스파크 어플리케이션 실행 중에 오류가 발생한 경우

- 하나의 스파크 잡이 전체 클러스터에서 성공되지만 다음 잡은 실패하는 경ㅇ
- 여러 단계로 처리되는 쿼리의 특정 단계가 실패하는 경우
- 어제 정상 동작한 예약 작업이 오늘 실패한 경우 등이 있다.
- 대응 방법은 다음과 같다.
    - 데이터가 존재하는지 데이터가 올바른 포맷인지 확인하자.
    - 포맥이 변경되었거나 일부 처리 과정이 변경되어서 의도하지 않은 결과를 초래했을 수 있다.
    - 만약 쿼리 실행 즉시 오류가 발생한다면 쿼리 실행 계획을 만드는 단계에서 발생한 분석 오류일 수 있다. 쿼리에 잘못된 컬럼명을 입력했거나 컬럼, 뷰, 테이블이 존재하지 않을 수 있다.
    - 어떤 연산자와 스테이지가 실행 중이었는지를 알아내기 위해서 Stack Trace 를 분석해서 단서를 찾아야 한다.
    - 입력 데이터와 데이터 포맷을 확인해봐야 한다. 스키마가 올바르게 지정되지 않았거나 특정 로우가 스키마 형태와 일치하지 않을 수 있다. 예를 들어서 null 을 허용하지 않았지만 실제 데이터에 null 이 있을 수 있다.
    - 데이터를 처리하는 코드에서 오류가 발생할 수 있다. 오류가 발생하면 스파크 로그에 오류 내용이 출력된다. 로그 파일을 분석해 오류 발생시 어떤 작업이 진행 중이었는지 확인할 수 있고 로그를 남겨서 정보를 파악하도록 해야한다.

### 느리거라 뒤쳐진 테스크

- 스파크 스테이지에서 대부분의 테스크가 정상적으로 실행되지만 소수의 테스크만 남아있는 경우. 남아 있는 테스크가 오래 실행되는 경우. 머신간의 작업이 균등하게 분배되지 않았거나, 특정 머신이 다른 머신보다 느린 경우.
- 스파크 어플리케이션을 실행하는 머신 수를 늘려도 상황이 개선되지 않고 여전히 특정 테스크가 다른 테스크보다 느린 경우
- 스파크 매트릭을 보면 Executor 에게 할당 받는 데이터가 차이가 많이 나는 경우
- 대응법은 다음과 같다.
    - 주로 DataFrame 이나 RDD 파티션에 데이터가 균등하게 분배되지 않아서 발생한다. 예를 들어서 Group-by-key 에서 특정 키가 월등하게 많은 경우가 이렇다.
    - 파티션 별 데이터를 줄이기 위해서 파티션 수를 증가시켜보자.
    - null 값이 많은 경우 먼저 필터링을 해보자.
    - 데이터 치우침이 심한 ID 칼럼을 파티셔닝 해보자.
    - Executor 의 메모리를 확인해보고 부족하다면 증가시켜보자.
    - 특정 머신의 디스크가 거의 가득 찼는지 확인해보자.
    - 사용자 저의 함수를 구현할 때 객체 할당이나 비즈니스 로직에서 쓸모 없는 부분이 있는지 확인하고 가능하면 DataFrame 코드로 변환하자.
    - 사용자 정의 함수나 사용자 정의 집계 함수가 적당한 크기의 데이터를 사용해서 실행하는지 확인하자. 집계 연산은 공통 키와 관련된 많은 데이터를 메모리에 적재하기 때문이다.
    - Dataset 을 다룰 때 문제가 발생할 수 있다. Dataset 은 사용자 정의 함수의 자바 객체로 변환하기 때문에 수많은 객체를 생성하므로 가비지 컬렉션이 빈번하게 발생할 수 있다. Dataset 을 이용한다면 가비지 컬렉션 매트릭이 느린 테스크와 관련 있는지 확인하자.


### 느린 집계 속도

- 집계 연산인 groupBy 속도가 느린 경우
- 집계 처리 이후의 잡이 느린 경우가 있다.
- 대응 방법은 다음과 같다.
    - 집계 연산 전에 파티션 수를 늘리면 테스크 별로 처리할 키 수를 줄일 수 있다.
    - Executor 의 메모리를 늘려서 디스크에 저장하는 빈도를 줄일 수 있다.
    - 집계 처리가 끝나고 이어서 실행되는 테스크가 느리다면 집계 처리된 데이터 셋에 불균형 현상이 남아 있다는 것이다. 이 경우 파티션을 임의로 재분배 할 수 있도록 repartition 명령을 추가하자.
    - 모든 필터와 SELECT 구문이 집계 연산보다 먼저 처리된다면 필요한 데이터를 기반으로 집계 연산을 수행할 수 있으르모 이를 이용하자.
    - null 값 대신에 빈 값을 사용하는 경우는 최적화를 할 수 없다. null 이 있는게 차라리 났다. null 은 skip 을 통한 최적화를 제공해줄 수 있다.
    - 일부 집게 함수는 다른 함수에 비해서 태생적으로 느리다. collect_list 와 collect_set 은 일치하느 모든 객체를 드라이버에 전송하기 때문에 아주 느리다.

### 느린 조인 속도

- 조인과 집계는 모두 셔플을 유발하기 떄문에 동일한 증상을 겪는다. (셔플은 데이터 재분배를 말한다.)
- 주로 조인 스테이지의 처리 시간이 오래 걸리는 경우가 있다.
- 대응법은 다음과 같다.
    - 많은 조인 연산을 다른 조인 타입으로 변경해서 최적화를 할 수 있다. 여러 조인 타입을 확인해보자.
    - 조인 순서를 변경하면서 Job 의 처리 속도가  올라가는지 확인해보자. 일부 조인은 많은 양의 데이터를 걸러낼 수 있으므로 이 작업을 먼저 해보는 것도 좋다.
    - 조인을 수행하기 전에 데이터셋을 분할하면 클러스터 노드 간 데이터 이동을 줄일 수 있다. 특히 동일한 데이터셋이 여러 조인연산에서 사용된다면 더욱 유용하다.
    - 모든 필터와 SELECT 구문이 조잉ㄴ 연산보다 우선 처리된다면 필요한 데이터만 이용해서 조인 연산을 수행할 수 있다.
    - 집계 연산과 마찬가지로 null 값이 빈 값보다 더 낫다.
    - 스파크는 입력 DataFrame 이나 테이블에 대한 통계가 없는 경우 브로드캐스트 조인을 사용하는 실행 계획을 생성하지 못한다. 조인 대상 테이블 중 하나가 작을 경우 강제로 브로드 캐스트 하거나 스파크의 통곗 수집 명령을 사용해 테이블을 분석해야한다.

### 느린 읽기와 쓰기 속도

- 느린 I/O 는 진단이 어려울 수 있다.
- 분산 파일 시스템이나 외부 시스템의 데이터를 읽는 속도가 느린 경우
- 네트워크 파일 시스템이나 blob 저장소에 데이터를 쓰는 속도가 느린 경우가 있다.
- 대응 방법은 다음과 같다.
    - spark.speculation 속성을 true 로 설정하면 느린 읽기와 쓰기 속도를 개선할 수 있다. 이 기능은 첫 번째 테스크에서 발생한 문제가 일시적인지 확인하기 위해 동일한 연산을 수행하는 테스크를 추가로 실행한다.
    - 네트워크 성능 문제를 확인한다.
    - 단일 클러스터에서 스파크와 HDFS 같은 분산 파일 시스템을 함께 구성하는 경우 클러스터의 노드마다 스파크와 분산 파일 시스템 모두 동일한 호스트명을 인식하는지 확인하자.

### 드라이버 OutofMemoryError

- 스파크 어플리케이션이 비정상적으로 종료된 문제로 드라이버에 너무 많은 데이터를 전송해서 메모리를 모두 소비한 경우에 자주 발생한다.
- 드라이버 로그에 OutofMemoryError 또는 가비지 컬렉션과 관련된 메시지가 출력되는 경우
- 명령이 장기간 실행되거나 실행되지 않는 경우
- 반응이 거의 없는 경우
- 드라이버 JVM 의 메모리 사용량이 많은 경우가 있다.
- 대응법은 다음과 같다.
    - 사용자 코드에서 collect() 메소드 연산을 실행해 너무 큰 데이터셋을 드라이버에 전송하려고 시도했을 수 있다.
    - 브로드캐스트 하기에 너무 큰 데이터를 브로드캐스트 조인에 사용했을 수 있다. 스파크의 최대 브로드캐스트 조인 설정을 이용해 제어해보자.
    - 자바의 jmap 도구를 사요해서 힙 메모리의 히스토그램을 확인해보자. JVM 내에서 객체 해제를 하는지 보고 가장 많이 차지하는 객체가 뭔지 확인해보자.
    - 가능하면 더 많은 데이터를 다룰 수 있도록 드라이버의 가용 메모리를 증가해보자.
    - 다른 언어를 혼용해서 사용하는 경우 두 언어간의 데이터 변환 과정에서 과도한 메모리를 사용할 수 있다.
    - 다른 사용자와 SparkContext 를 공유하는 사오항이라면 대량의 데이터를 드라이버에 보낼 수 있으므롲 주의하자.

### Executor OutofMemoryError 또는 응답 없음

- 문제의 근본 원인에 따라 다르곘지만 어떤 경우에는 스파크 어플리케이션이 문제를 자동으로 복구할 수 있다.
- Executor 로그에 OutofMemoryError 또는 가비지 컬렉션과 관련된 메시지가 스파크 UI 에 뜨는 경우
- Executor 가 비정상적으로 종료되거나 응답하지 않는 경우
- 대응법은 다음과 같다.
    - Executor 의 메모리 수를 늘린다.
    - 실행중인 테스크에서 너무 많은 객체를 생성하고 있어서 GC 가 일어나서 그런것일 수 있다. 이는 사용자 정의 함수를 사용하는 경우에 발생할 확률이 높다. 이 경우 데이터 파티션을 재분배하면 병렬성을 높일 수 있어서 테스크 별로 처리해아하는 레코드를 줄일 수 있다. 모든 Executor 에 동일한 양의 작업이 할당되는지 보자.
    - RDD 와 Dataset 은 객체를 생서하기 때문에 이 문제가 발생할 확률이 더 높다.  UDF 를 줄이고 스파크의 구조적 API 를 많이 사용하자.
    - 자바의 jmap 을 이용해서 가장 많은 메모리를 차지하는 클래스를 확인해보자.
    - 키 값 저장소 같이 다른 워크로드를 처리하는 노드에 익스큐터가 있다면 이를 다른 잡과 분리하자.

### 의도하지 않는 null 값이 있는 결과 데이터

- 트랜스포메이션이 실행된 결과에 의도치 않은 null 값이 있는 경우.
- 잘 동작하던 운영 환경의 작업이 동작하지 않거나 정확한 결과를 생성하지 못하는 경우.
- 대응 방법은 다음과 같다.
    - 비즈니스 로직을 변경하지 않았더라면 데이터 포맷이 변경되었을 수 있다.
    - Accumulator 를 사용해 레코드나 특정 데이터 타입의 수를 확인할 수 있다. 이 방식으로 레코드를 건너뛰는 오류도 분석할 수 있다. 에를 들어 특정 포맷의 데이터를 파싱하던 중 일부 데이터가 파싱되지 않았더라면 이 방법이 유용할 수 있다. 대부분의 경우 원시 데이터를 파싱할 때 개수를 세기 위한 용도로 Accumulator 가 탑재된 사용자 정의 함수를 사용한다. 어큐뮬레이터로 정상과 비정상 레코드를 확인할 수 있고 결과에 따라 상황에 맞는 명령을 수행할 수 있다.
    - 트랜스포메이션이 실제 유요한 쿼리 실행 계획을 생성하는지 확인해보자. 스파크 SQL 에서 암시적 형변환을 수행하는 경우 혼란스러운 결과가 반환될 수 있다. 예를 들어 SELECT 5 * “23” 은 문자열 23 이 숫자 23 으로 암시적 형변환이 되어서 115 를 반환하지만 SELECT 5 * “ “ 는 빈 문자열이 null 로 변환되므로 결국 null 값을 반환한다. 그러므로 중간 데이터셋이 의도한 대로 만들어 졌는지 printSchema 메소드를 사용하자. 그리고 최종 쿼리 실행 계획에 있는 모든 CAST 연산을 찾아서 확인해야 한다.

### 디스크 공간 없음 오류

- ‘no space left on disk’ 오류 메시지와 함께 잡이 실패하는 경우가 있다.
- 대응법은 다음과 같다.
    - 더 많은 디스크 공간을 확보하면 된다. 작업 노드의 디스크를 늘리거나 클라우드 환경의 외부 저장소를 추가하면 된다.
    - 제한된 용량의 저장소를 사용하는 경우 데이터 치우침 현상이 발생한다면 일부 노드의 저장소 공간이 모두 소진될 수 있다. 이 경우 데이터 파이션을 재분배하자.
    - 문제가 되는 머신의 오래된 로그 파일과 셔플 파일을 수동으로 제거하자.

### 직렬화 오류

- 직렬화 오류와 함께 잡이 실패하는 경우가 있다.
- 대응법은 다음과 같다.
    - 구조적 API 를 사용하는 경우 직렬화 오류는 거의 없다. 하지만 UDF 나 RDD 를 사용하는 경우 익스큐터에는 이게 발생할 수 있다. 이 경우에는 직렬화 할 수 없는 코드 또는 데이터를 다루거나 이상한 데이터 타입을 다루는 경우에 발생한다.
